{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNHFNxN2Aubrot/gHcNmuJo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmy93029/Selected_topic_for_RL_sophomore_fall/blob/master/lab2_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 強化學習專論 lab2 Colab code"
      ],
      "metadata": {
        "id": "3tP4u6nFfXHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "enviroment"
      ],
      "metadata": {
        "id": "uPu4wM_1gH09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install \"gym[atari, accept-rom-license]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsnPrYcLiRIA",
        "outputId": "6be3a3dd-a846-4504-b987-cf4707ccad70"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (0.4.2)\n",
            "Requirement already satisfied: ale-py~=0.7.5 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license,atari]) (0.7.5)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (6.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.66.1)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from collections import deque\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from abc import ABC, abstractmethod"
      ],
      "metadata": {
        "id": "9wMunz7IgO_D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "import random"
      ],
      "metadata": {
        "id": "RJ9OzqcugGnq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import gymnasium as gym"
      ],
      "metadata": {
        "id": "fS_h6RNUh63J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ale_py\n",
        "\n",
        "print(gym.envs.registry.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vBmv4q3kAmx",
        "outputId": "e974b4b5-79c8-47fd-f089-07986e6e577f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'phys2d/CartPole-v0', 'phys2d/CartPole-v1', 'phys2d/Pendulum-v0', 'LunarLander-v2', 'LunarLanderContinuous-v2', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v2', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'tabular/Blackjack-v0', 'tabular/CliffWalking-v0', 'Reacher-v2', 'Reacher-v4', 'Pusher-v2', 'Pusher-v4', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'HumanoidStandup-v2', 'HumanoidStandup-v4', 'GymV26Environment-v0', 'GymV21Environment-v0', 'Adventure-v0', 'AdventureDeterministic-v0', 'AdventureNoFrameskip-v0', 'Adventure-v4', 'AdventureDeterministic-v4', 'AdventureNoFrameskip-v4', 'Adventure-ram-v0', 'Adventure-ramDeterministic-v0', 'Adventure-ramNoFrameskip-v0', 'Adventure-ram-v4', 'Adventure-ramDeterministic-v4', 'Adventure-ramNoFrameskip-v4', 'AirRaid-v0', 'AirRaidDeterministic-v0', 'AirRaidNoFrameskip-v0', 'AirRaid-v4', 'AirRaidDeterministic-v4', 'AirRaidNoFrameskip-v4', 'AirRaid-ram-v0', 'AirRaid-ramDeterministic-v0', 'AirRaid-ramNoFrameskip-v0', 'AirRaid-ram-v4', 'AirRaid-ramDeterministic-v4', 'AirRaid-ramNoFrameskip-v4', 'Alien-v0', 'AlienDeterministic-v0', 'AlienNoFrameskip-v0', 'Alien-v4', 'AlienDeterministic-v4', 'AlienNoFrameskip-v4', 'Alien-ram-v0', 'Alien-ramDeterministic-v0', 'Alien-ramNoFrameskip-v0', 'Alien-ram-v4', 'Alien-ramDeterministic-v4', 'Alien-ramNoFrameskip-v4', 'Amidar-v0', 'AmidarDeterministic-v0', 'AmidarNoFrameskip-v0', 'Amidar-v4', 'AmidarDeterministic-v4', 'AmidarNoFrameskip-v4', 'Amidar-ram-v0', 'Amidar-ramDeterministic-v0', 'Amidar-ramNoFrameskip-v0', 'Amidar-ram-v4', 'Amidar-ramDeterministic-v4', 'Amidar-ramNoFrameskip-v4', 'Assault-v0', 'AssaultDeterministic-v0', 'AssaultNoFrameskip-v0', 'Assault-v4', 'AssaultDeterministic-v4', 'AssaultNoFrameskip-v4', 'Assault-ram-v0', 'Assault-ramDeterministic-v0', 'Assault-ramNoFrameskip-v0', 'Assault-ram-v4', 'Assault-ramDeterministic-v4', 'Assault-ramNoFrameskip-v4', 'Asterix-v0', 'AsterixDeterministic-v0', 'AsterixNoFrameskip-v0', 'Asterix-v4', 'AsterixDeterministic-v4', 'AsterixNoFrameskip-v4', 'Asterix-ram-v0', 'Asterix-ramDeterministic-v0', 'Asterix-ramNoFrameskip-v0', 'Asterix-ram-v4', 'Asterix-ramDeterministic-v4', 'Asterix-ramNoFrameskip-v4', 'Asteroids-v0', 'AsteroidsDeterministic-v0', 'AsteroidsNoFrameskip-v0', 'Asteroids-v4', 'AsteroidsDeterministic-v4', 'AsteroidsNoFrameskip-v4', 'Asteroids-ram-v0', 'Asteroids-ramDeterministic-v0', 'Asteroids-ramNoFrameskip-v0', 'Asteroids-ram-v4', 'Asteroids-ramDeterministic-v4', 'Asteroids-ramNoFrameskip-v4', 'Atlantis-v0', 'AtlantisDeterministic-v0', 'AtlantisNoFrameskip-v0', 'Atlantis-v4', 'AtlantisDeterministic-v4', 'AtlantisNoFrameskip-v4', 'Atlantis-ram-v0', 'Atlantis-ramDeterministic-v0', 'Atlantis-ramNoFrameskip-v0', 'Atlantis-ram-v4', 'Atlantis-ramDeterministic-v4', 'Atlantis-ramNoFrameskip-v4', 'BankHeist-v0', 'BankHeistDeterministic-v0', 'BankHeistNoFrameskip-v0', 'BankHeist-v4', 'BankHeistDeterministic-v4', 'BankHeistNoFrameskip-v4', 'BankHeist-ram-v0', 'BankHeist-ramDeterministic-v0', 'BankHeist-ramNoFrameskip-v0', 'BankHeist-ram-v4', 'BankHeist-ramDeterministic-v4', 'BankHeist-ramNoFrameskip-v4', 'BattleZone-v0', 'BattleZoneDeterministic-v0', 'BattleZoneNoFrameskip-v0', 'BattleZone-v4', 'BattleZoneDeterministic-v4', 'BattleZoneNoFrameskip-v4', 'BattleZone-ram-v0', 'BattleZone-ramDeterministic-v0', 'BattleZone-ramNoFrameskip-v0', 'BattleZone-ram-v4', 'BattleZone-ramDeterministic-v4', 'BattleZone-ramNoFrameskip-v4', 'BeamRider-v0', 'BeamRiderDeterministic-v0', 'BeamRiderNoFrameskip-v0', 'BeamRider-v4', 'BeamRiderDeterministic-v4', 'BeamRiderNoFrameskip-v4', 'BeamRider-ram-v0', 'BeamRider-ramDeterministic-v0', 'BeamRider-ramNoFrameskip-v0', 'BeamRider-ram-v4', 'BeamRider-ramDeterministic-v4', 'BeamRider-ramNoFrameskip-v4', 'Berzerk-v0', 'BerzerkDeterministic-v0', 'BerzerkNoFrameskip-v0', 'Berzerk-v4', 'BerzerkDeterministic-v4', 'BerzerkNoFrameskip-v4', 'Berzerk-ram-v0', 'Berzerk-ramDeterministic-v0', 'Berzerk-ramNoFrameskip-v0', 'Berzerk-ram-v4', 'Berzerk-ramDeterministic-v4', 'Berzerk-ramNoFrameskip-v4', 'Bowling-v0', 'BowlingDeterministic-v0', 'BowlingNoFrameskip-v0', 'Bowling-v4', 'BowlingDeterministic-v4', 'BowlingNoFrameskip-v4', 'Bowling-ram-v0', 'Bowling-ramDeterministic-v0', 'Bowling-ramNoFrameskip-v0', 'Bowling-ram-v4', 'Bowling-ramDeterministic-v4', 'Bowling-ramNoFrameskip-v4', 'Boxing-v0', 'BoxingDeterministic-v0', 'BoxingNoFrameskip-v0', 'Boxing-v4', 'BoxingDeterministic-v4', 'BoxingNoFrameskip-v4', 'Boxing-ram-v0', 'Boxing-ramDeterministic-v0', 'Boxing-ramNoFrameskip-v0', 'Boxing-ram-v4', 'Boxing-ramDeterministic-v4', 'Boxing-ramNoFrameskip-v4', 'Breakout-v0', 'BreakoutDeterministic-v0', 'BreakoutNoFrameskip-v0', 'Breakout-v4', 'BreakoutDeterministic-v4', 'BreakoutNoFrameskip-v4', 'Breakout-ram-v0', 'Breakout-ramDeterministic-v0', 'Breakout-ramNoFrameskip-v0', 'Breakout-ram-v4', 'Breakout-ramDeterministic-v4', 'Breakout-ramNoFrameskip-v4', 'Carnival-v0', 'CarnivalDeterministic-v0', 'CarnivalNoFrameskip-v0', 'Carnival-v4', 'CarnivalDeterministic-v4', 'CarnivalNoFrameskip-v4', 'Carnival-ram-v0', 'Carnival-ramDeterministic-v0', 'Carnival-ramNoFrameskip-v0', 'Carnival-ram-v4', 'Carnival-ramDeterministic-v4', 'Carnival-ramNoFrameskip-v4', 'Centipede-v0', 'CentipedeDeterministic-v0', 'CentipedeNoFrameskip-v0', 'Centipede-v4', 'CentipedeDeterministic-v4', 'CentipedeNoFrameskip-v4', 'Centipede-ram-v0', 'Centipede-ramDeterministic-v0', 'Centipede-ramNoFrameskip-v0', 'Centipede-ram-v4', 'Centipede-ramDeterministic-v4', 'Centipede-ramNoFrameskip-v4', 'ChopperCommand-v0', 'ChopperCommandDeterministic-v0', 'ChopperCommandNoFrameskip-v0', 'ChopperCommand-v4', 'ChopperCommandDeterministic-v4', 'ChopperCommandNoFrameskip-v4', 'ChopperCommand-ram-v0', 'ChopperCommand-ramDeterministic-v0', 'ChopperCommand-ramNoFrameskip-v0', 'ChopperCommand-ram-v4', 'ChopperCommand-ramDeterministic-v4', 'ChopperCommand-ramNoFrameskip-v4', 'CrazyClimber-v0', 'CrazyClimberDeterministic-v0', 'CrazyClimberNoFrameskip-v0', 'CrazyClimber-v4', 'CrazyClimberDeterministic-v4', 'CrazyClimberNoFrameskip-v4', 'CrazyClimber-ram-v0', 'CrazyClimber-ramDeterministic-v0', 'CrazyClimber-ramNoFrameskip-v0', 'CrazyClimber-ram-v4', 'CrazyClimber-ramDeterministic-v4', 'CrazyClimber-ramNoFrameskip-v4', 'Defender-v0', 'DefenderDeterministic-v0', 'DefenderNoFrameskip-v0', 'Defender-v4', 'DefenderDeterministic-v4', 'DefenderNoFrameskip-v4', 'Defender-ram-v0', 'Defender-ramDeterministic-v0', 'Defender-ramNoFrameskip-v0', 'Defender-ram-v4', 'Defender-ramDeterministic-v4', 'Defender-ramNoFrameskip-v4', 'DemonAttack-v0', 'DemonAttackDeterministic-v0', 'DemonAttackNoFrameskip-v0', 'DemonAttack-v4', 'DemonAttackDeterministic-v4', 'DemonAttackNoFrameskip-v4', 'DemonAttack-ram-v0', 'DemonAttack-ramDeterministic-v0', 'DemonAttack-ramNoFrameskip-v0', 'DemonAttack-ram-v4', 'DemonAttack-ramDeterministic-v4', 'DemonAttack-ramNoFrameskip-v4', 'DoubleDunk-v0', 'DoubleDunkDeterministic-v0', 'DoubleDunkNoFrameskip-v0', 'DoubleDunk-v4', 'DoubleDunkDeterministic-v4', 'DoubleDunkNoFrameskip-v4', 'DoubleDunk-ram-v0', 'DoubleDunk-ramDeterministic-v0', 'DoubleDunk-ramNoFrameskip-v0', 'DoubleDunk-ram-v4', 'DoubleDunk-ramDeterministic-v4', 'DoubleDunk-ramNoFrameskip-v4', 'ElevatorAction-v0', 'ElevatorActionDeterministic-v0', 'ElevatorActionNoFrameskip-v0', 'ElevatorAction-v4', 'ElevatorActionDeterministic-v4', 'ElevatorActionNoFrameskip-v4', 'ElevatorAction-ram-v0', 'ElevatorAction-ramDeterministic-v0', 'ElevatorAction-ramNoFrameskip-v0', 'ElevatorAction-ram-v4', 'ElevatorAction-ramDeterministic-v4', 'ElevatorAction-ramNoFrameskip-v4', 'Enduro-v0', 'EnduroDeterministic-v0', 'EnduroNoFrameskip-v0', 'Enduro-v4', 'EnduroDeterministic-v4', 'EnduroNoFrameskip-v4', 'Enduro-ram-v0', 'Enduro-ramDeterministic-v0', 'Enduro-ramNoFrameskip-v0', 'Enduro-ram-v4', 'Enduro-ramDeterministic-v4', 'Enduro-ramNoFrameskip-v4', 'FishingDerby-v0', 'FishingDerbyDeterministic-v0', 'FishingDerbyNoFrameskip-v0', 'FishingDerby-v4', 'FishingDerbyDeterministic-v4', 'FishingDerbyNoFrameskip-v4', 'FishingDerby-ram-v0', 'FishingDerby-ramDeterministic-v0', 'FishingDerby-ramNoFrameskip-v0', 'FishingDerby-ram-v4', 'FishingDerby-ramDeterministic-v4', 'FishingDerby-ramNoFrameskip-v4', 'Freeway-v0', 'FreewayDeterministic-v0', 'FreewayNoFrameskip-v0', 'Freeway-v4', 'FreewayDeterministic-v4', 'FreewayNoFrameskip-v4', 'Freeway-ram-v0', 'Freeway-ramDeterministic-v0', 'Freeway-ramNoFrameskip-v0', 'Freeway-ram-v4', 'Freeway-ramDeterministic-v4', 'Freeway-ramNoFrameskip-v4', 'Frostbite-v0', 'FrostbiteDeterministic-v0', 'FrostbiteNoFrameskip-v0', 'Frostbite-v4', 'FrostbiteDeterministic-v4', 'FrostbiteNoFrameskip-v4', 'Frostbite-ram-v0', 'Frostbite-ramDeterministic-v0', 'Frostbite-ramNoFrameskip-v0', 'Frostbite-ram-v4', 'Frostbite-ramDeterministic-v4', 'Frostbite-ramNoFrameskip-v4', 'Gopher-v0', 'GopherDeterministic-v0', 'GopherNoFrameskip-v0', 'Gopher-v4', 'GopherDeterministic-v4', 'GopherNoFrameskip-v4', 'Gopher-ram-v0', 'Gopher-ramDeterministic-v0', 'Gopher-ramNoFrameskip-v0', 'Gopher-ram-v4', 'Gopher-ramDeterministic-v4', 'Gopher-ramNoFrameskip-v4', 'Gravitar-v0', 'GravitarDeterministic-v0', 'GravitarNoFrameskip-v0', 'Gravitar-v4', 'GravitarDeterministic-v4', 'GravitarNoFrameskip-v4', 'Gravitar-ram-v0', 'Gravitar-ramDeterministic-v0', 'Gravitar-ramNoFrameskip-v0', 'Gravitar-ram-v4', 'Gravitar-ramDeterministic-v4', 'Gravitar-ramNoFrameskip-v4', 'Hero-v0', 'HeroDeterministic-v0', 'HeroNoFrameskip-v0', 'Hero-v4', 'HeroDeterministic-v4', 'HeroNoFrameskip-v4', 'Hero-ram-v0', 'Hero-ramDeterministic-v0', 'Hero-ramNoFrameskip-v0', 'Hero-ram-v4', 'Hero-ramDeterministic-v4', 'Hero-ramNoFrameskip-v4', 'IceHockey-v0', 'IceHockeyDeterministic-v0', 'IceHockeyNoFrameskip-v0', 'IceHockey-v4', 'IceHockeyDeterministic-v4', 'IceHockeyNoFrameskip-v4', 'IceHockey-ram-v0', 'IceHockey-ramDeterministic-v0', 'IceHockey-ramNoFrameskip-v0', 'IceHockey-ram-v4', 'IceHockey-ramDeterministic-v4', 'IceHockey-ramNoFrameskip-v4', 'Jamesbond-v0', 'JamesbondDeterministic-v0', 'JamesbondNoFrameskip-v0', 'Jamesbond-v4', 'JamesbondDeterministic-v4', 'JamesbondNoFrameskip-v4', 'Jamesbond-ram-v0', 'Jamesbond-ramDeterministic-v0', 'Jamesbond-ramNoFrameskip-v0', 'Jamesbond-ram-v4', 'Jamesbond-ramDeterministic-v4', 'Jamesbond-ramNoFrameskip-v4', 'JourneyEscape-v0', 'JourneyEscapeDeterministic-v0', 'JourneyEscapeNoFrameskip-v0', 'JourneyEscape-v4', 'JourneyEscapeDeterministic-v4', 'JourneyEscapeNoFrameskip-v4', 'JourneyEscape-ram-v0', 'JourneyEscape-ramDeterministic-v0', 'JourneyEscape-ramNoFrameskip-v0', 'JourneyEscape-ram-v4', 'JourneyEscape-ramDeterministic-v4', 'JourneyEscape-ramNoFrameskip-v4', 'Kangaroo-v0', 'KangarooDeterministic-v0', 'KangarooNoFrameskip-v0', 'Kangaroo-v4', 'KangarooDeterministic-v4', 'KangarooNoFrameskip-v4', 'Kangaroo-ram-v0', 'Kangaroo-ramDeterministic-v0', 'Kangaroo-ramNoFrameskip-v0', 'Kangaroo-ram-v4', 'Kangaroo-ramDeterministic-v4', 'Kangaroo-ramNoFrameskip-v4', 'Krull-v0', 'KrullDeterministic-v0', 'KrullNoFrameskip-v0', 'Krull-v4', 'KrullDeterministic-v4', 'KrullNoFrameskip-v4', 'Krull-ram-v0', 'Krull-ramDeterministic-v0', 'Krull-ramNoFrameskip-v0', 'Krull-ram-v4', 'Krull-ramDeterministic-v4', 'Krull-ramNoFrameskip-v4', 'KungFuMaster-v0', 'KungFuMasterDeterministic-v0', 'KungFuMasterNoFrameskip-v0', 'KungFuMaster-v4', 'KungFuMasterDeterministic-v4', 'KungFuMasterNoFrameskip-v4', 'KungFuMaster-ram-v0', 'KungFuMaster-ramDeterministic-v0', 'KungFuMaster-ramNoFrameskip-v0', 'KungFuMaster-ram-v4', 'KungFuMaster-ramDeterministic-v4', 'KungFuMaster-ramNoFrameskip-v4', 'MontezumaRevenge-v0', 'MontezumaRevengeDeterministic-v0', 'MontezumaRevengeNoFrameskip-v0', 'MontezumaRevenge-v4', 'MontezumaRevengeDeterministic-v4', 'MontezumaRevengeNoFrameskip-v4', 'MontezumaRevenge-ram-v0', 'MontezumaRevenge-ramDeterministic-v0', 'MontezumaRevenge-ramNoFrameskip-v0', 'MontezumaRevenge-ram-v4', 'MontezumaRevenge-ramDeterministic-v4', 'MontezumaRevenge-ramNoFrameskip-v4', 'MsPacman-v0', 'MsPacmanDeterministic-v0', 'MsPacmanNoFrameskip-v0', 'MsPacman-v4', 'MsPacmanDeterministic-v4', 'MsPacmanNoFrameskip-v4', 'MsPacman-ram-v0', 'MsPacman-ramDeterministic-v0', 'MsPacman-ramNoFrameskip-v0', 'MsPacman-ram-v4', 'MsPacman-ramDeterministic-v4', 'MsPacman-ramNoFrameskip-v4', 'NameThisGame-v0', 'NameThisGameDeterministic-v0', 'NameThisGameNoFrameskip-v0', 'NameThisGame-v4', 'NameThisGameDeterministic-v4', 'NameThisGameNoFrameskip-v4', 'NameThisGame-ram-v0', 'NameThisGame-ramDeterministic-v0', 'NameThisGame-ramNoFrameskip-v0', 'NameThisGame-ram-v4', 'NameThisGame-ramDeterministic-v4', 'NameThisGame-ramNoFrameskip-v4', 'Phoenix-v0', 'PhoenixDeterministic-v0', 'PhoenixNoFrameskip-v0', 'Phoenix-v4', 'PhoenixDeterministic-v4', 'PhoenixNoFrameskip-v4', 'Phoenix-ram-v0', 'Phoenix-ramDeterministic-v0', 'Phoenix-ramNoFrameskip-v0', 'Phoenix-ram-v4', 'Phoenix-ramDeterministic-v4', 'Phoenix-ramNoFrameskip-v4', 'Pitfall-v0', 'PitfallDeterministic-v0', 'PitfallNoFrameskip-v0', 'Pitfall-v4', 'PitfallDeterministic-v4', 'PitfallNoFrameskip-v4', 'Pitfall-ram-v0', 'Pitfall-ramDeterministic-v0', 'Pitfall-ramNoFrameskip-v0', 'Pitfall-ram-v4', 'Pitfall-ramDeterministic-v4', 'Pitfall-ramNoFrameskip-v4', 'Pong-v0', 'PongDeterministic-v0', 'PongNoFrameskip-v0', 'Pong-v4', 'PongDeterministic-v4', 'PongNoFrameskip-v4', 'Pong-ram-v0', 'Pong-ramDeterministic-v0', 'Pong-ramNoFrameskip-v0', 'Pong-ram-v4', 'Pong-ramDeterministic-v4', 'Pong-ramNoFrameskip-v4', 'Pooyan-v0', 'PooyanDeterministic-v0', 'PooyanNoFrameskip-v0', 'Pooyan-v4', 'PooyanDeterministic-v4', 'PooyanNoFrameskip-v4', 'Pooyan-ram-v0', 'Pooyan-ramDeterministic-v0', 'Pooyan-ramNoFrameskip-v0', 'Pooyan-ram-v4', 'Pooyan-ramDeterministic-v4', 'Pooyan-ramNoFrameskip-v4', 'PrivateEye-v0', 'PrivateEyeDeterministic-v0', 'PrivateEyeNoFrameskip-v0', 'PrivateEye-v4', 'PrivateEyeDeterministic-v4', 'PrivateEyeNoFrameskip-v4', 'PrivateEye-ram-v0', 'PrivateEye-ramDeterministic-v0', 'PrivateEye-ramNoFrameskip-v0', 'PrivateEye-ram-v4', 'PrivateEye-ramDeterministic-v4', 'PrivateEye-ramNoFrameskip-v4', 'Qbert-v0', 'QbertDeterministic-v0', 'QbertNoFrameskip-v0', 'Qbert-v4', 'QbertDeterministic-v4', 'QbertNoFrameskip-v4', 'Qbert-ram-v0', 'Qbert-ramDeterministic-v0', 'Qbert-ramNoFrameskip-v0', 'Qbert-ram-v4', 'Qbert-ramDeterministic-v4', 'Qbert-ramNoFrameskip-v4', 'Riverraid-v0', 'RiverraidDeterministic-v0', 'RiverraidNoFrameskip-v0', 'Riverraid-v4', 'RiverraidDeterministic-v4', 'RiverraidNoFrameskip-v4', 'Riverraid-ram-v0', 'Riverraid-ramDeterministic-v0', 'Riverraid-ramNoFrameskip-v0', 'Riverraid-ram-v4', 'Riverraid-ramDeterministic-v4', 'Riverraid-ramNoFrameskip-v4', 'RoadRunner-v0', 'RoadRunnerDeterministic-v0', 'RoadRunnerNoFrameskip-v0', 'RoadRunner-v4', 'RoadRunnerDeterministic-v4', 'RoadRunnerNoFrameskip-v4', 'RoadRunner-ram-v0', 'RoadRunner-ramDeterministic-v0', 'RoadRunner-ramNoFrameskip-v0', 'RoadRunner-ram-v4', 'RoadRunner-ramDeterministic-v4', 'RoadRunner-ramNoFrameskip-v4', 'Robotank-v0', 'RobotankDeterministic-v0', 'RobotankNoFrameskip-v0', 'Robotank-v4', 'RobotankDeterministic-v4', 'RobotankNoFrameskip-v4', 'Robotank-ram-v0', 'Robotank-ramDeterministic-v0', 'Robotank-ramNoFrameskip-v0', 'Robotank-ram-v4', 'Robotank-ramDeterministic-v4', 'Robotank-ramNoFrameskip-v4', 'Seaquest-v0', 'SeaquestDeterministic-v0', 'SeaquestNoFrameskip-v0', 'Seaquest-v4', 'SeaquestDeterministic-v4', 'SeaquestNoFrameskip-v4', 'Seaquest-ram-v0', 'Seaquest-ramDeterministic-v0', 'Seaquest-ramNoFrameskip-v0', 'Seaquest-ram-v4', 'Seaquest-ramDeterministic-v4', 'Seaquest-ramNoFrameskip-v4', 'Skiing-v0', 'SkiingDeterministic-v0', 'SkiingNoFrameskip-v0', 'Skiing-v4', 'SkiingDeterministic-v4', 'SkiingNoFrameskip-v4', 'Skiing-ram-v0', 'Skiing-ramDeterministic-v0', 'Skiing-ramNoFrameskip-v0', 'Skiing-ram-v4', 'Skiing-ramDeterministic-v4', 'Skiing-ramNoFrameskip-v4', 'Solaris-v0', 'SolarisDeterministic-v0', 'SolarisNoFrameskip-v0', 'Solaris-v4', 'SolarisDeterministic-v4', 'SolarisNoFrameskip-v4', 'Solaris-ram-v0', 'Solaris-ramDeterministic-v0', 'Solaris-ramNoFrameskip-v0', 'Solaris-ram-v4', 'Solaris-ramDeterministic-v4', 'Solaris-ramNoFrameskip-v4', 'SpaceInvaders-v0', 'SpaceInvadersDeterministic-v0', 'SpaceInvadersNoFrameskip-v0', 'SpaceInvaders-v4', 'SpaceInvadersDeterministic-v4', 'SpaceInvadersNoFrameskip-v4', 'SpaceInvaders-ram-v0', 'SpaceInvaders-ramDeterministic-v0', 'SpaceInvaders-ramNoFrameskip-v0', 'SpaceInvaders-ram-v4', 'SpaceInvaders-ramDeterministic-v4', 'SpaceInvaders-ramNoFrameskip-v4', 'StarGunner-v0', 'StarGunnerDeterministic-v0', 'StarGunnerNoFrameskip-v0', 'StarGunner-v4', 'StarGunnerDeterministic-v4', 'StarGunnerNoFrameskip-v4', 'StarGunner-ram-v0', 'StarGunner-ramDeterministic-v0', 'StarGunner-ramNoFrameskip-v0', 'StarGunner-ram-v4', 'StarGunner-ramDeterministic-v4', 'StarGunner-ramNoFrameskip-v4', 'Tennis-v0', 'TennisDeterministic-v0', 'TennisNoFrameskip-v0', 'Tennis-v4', 'TennisDeterministic-v4', 'TennisNoFrameskip-v4', 'Tennis-ram-v0', 'Tennis-ramDeterministic-v0', 'Tennis-ramNoFrameskip-v0', 'Tennis-ram-v4', 'Tennis-ramDeterministic-v4', 'Tennis-ramNoFrameskip-v4', 'TimePilot-v0', 'TimePilotDeterministic-v0', 'TimePilotNoFrameskip-v0', 'TimePilot-v4', 'TimePilotDeterministic-v4', 'TimePilotNoFrameskip-v4', 'TimePilot-ram-v0', 'TimePilot-ramDeterministic-v0', 'TimePilot-ramNoFrameskip-v0', 'TimePilot-ram-v4', 'TimePilot-ramDeterministic-v4', 'TimePilot-ramNoFrameskip-v4', 'Tutankham-v0', 'TutankhamDeterministic-v0', 'TutankhamNoFrameskip-v0', 'Tutankham-v4', 'TutankhamDeterministic-v4', 'TutankhamNoFrameskip-v4', 'Tutankham-ram-v0', 'Tutankham-ramDeterministic-v0', 'Tutankham-ramNoFrameskip-v0', 'Tutankham-ram-v4', 'Tutankham-ramDeterministic-v4', 'Tutankham-ramNoFrameskip-v4', 'UpNDown-v0', 'UpNDownDeterministic-v0', 'UpNDownNoFrameskip-v0', 'UpNDown-v4', 'UpNDownDeterministic-v4', 'UpNDownNoFrameskip-v4', 'UpNDown-ram-v0', 'UpNDown-ramDeterministic-v0', 'UpNDown-ramNoFrameskip-v0', 'UpNDown-ram-v4', 'UpNDown-ramDeterministic-v4', 'UpNDown-ramNoFrameskip-v4', 'Venture-v0', 'VentureDeterministic-v0', 'VentureNoFrameskip-v0', 'Venture-v4', 'VentureDeterministic-v4', 'VentureNoFrameskip-v4', 'Venture-ram-v0', 'Venture-ramDeterministic-v0', 'Venture-ramNoFrameskip-v0', 'Venture-ram-v4', 'Venture-ramDeterministic-v4', 'Venture-ramNoFrameskip-v4', 'VideoPinball-v0', 'VideoPinballDeterministic-v0', 'VideoPinballNoFrameskip-v0', 'VideoPinball-v4', 'VideoPinballDeterministic-v4', 'VideoPinballNoFrameskip-v4', 'VideoPinball-ram-v0', 'VideoPinball-ramDeterministic-v0', 'VideoPinball-ramNoFrameskip-v0', 'VideoPinball-ram-v4', 'VideoPinball-ramDeterministic-v4', 'VideoPinball-ramNoFrameskip-v4', 'WizardOfWor-v0', 'WizardOfWorDeterministic-v0', 'WizardOfWorNoFrameskip-v0', 'WizardOfWor-v4', 'WizardOfWorDeterministic-v4', 'WizardOfWorNoFrameskip-v4', 'WizardOfWor-ram-v0', 'WizardOfWor-ramDeterministic-v0', 'WizardOfWor-ramNoFrameskip-v0', 'WizardOfWor-ram-v4', 'WizardOfWor-ramDeterministic-v4', 'WizardOfWor-ramNoFrameskip-v4', 'YarsRevenge-v0', 'YarsRevengeDeterministic-v0', 'YarsRevengeNoFrameskip-v0', 'YarsRevenge-v4', 'YarsRevengeDeterministic-v4', 'YarsRevengeNoFrameskip-v4', 'YarsRevenge-ram-v0', 'YarsRevenge-ramDeterministic-v0', 'YarsRevenge-ramNoFrameskip-v0', 'YarsRevenge-ram-v4', 'YarsRevenge-ramDeterministic-v4', 'YarsRevenge-ramNoFrameskip-v4', 'Zaxxon-v0', 'ZaxxonDeterministic-v0', 'ZaxxonNoFrameskip-v0', 'Zaxxon-v4', 'ZaxxonDeterministic-v4', 'ZaxxonNoFrameskip-v4', 'Zaxxon-ram-v0', 'Zaxxon-ramDeterministic-v0', 'Zaxxon-ramNoFrameskip-v0', 'Zaxxon-ram-v4', 'Zaxxon-ramDeterministic-v4', 'Zaxxon-ramNoFrameskip-v4', 'ALE/Adventure-v5', 'ALE/Adventure-ram-v5', 'ALE/AirRaid-v5', 'ALE/AirRaid-ram-v5', 'ALE/Alien-v5', 'ALE/Alien-ram-v5', 'ALE/Amidar-v5', 'ALE/Amidar-ram-v5', 'ALE/Assault-v5', 'ALE/Assault-ram-v5', 'ALE/Asterix-v5', 'ALE/Asterix-ram-v5', 'ALE/Asteroids-v5', 'ALE/Asteroids-ram-v5', 'ALE/Atlantis-v5', 'ALE/Atlantis-ram-v5', 'ALE/Atlantis2-v5', 'ALE/Atlantis2-ram-v5', 'ALE/Backgammon-v5', 'ALE/Backgammon-ram-v5', 'ALE/BankHeist-v5', 'ALE/BankHeist-ram-v5', 'ALE/BasicMath-v5', 'ALE/BasicMath-ram-v5', 'ALE/BattleZone-v5', 'ALE/BattleZone-ram-v5', 'ALE/BeamRider-v5', 'ALE/BeamRider-ram-v5', 'ALE/Berzerk-v5', 'ALE/Berzerk-ram-v5', 'ALE/Blackjack-v5', 'ALE/Blackjack-ram-v5', 'ALE/Bowling-v5', 'ALE/Bowling-ram-v5', 'ALE/Boxing-v5', 'ALE/Boxing-ram-v5', 'ALE/Breakout-v5', 'ALE/Breakout-ram-v5', 'ALE/Carnival-v5', 'ALE/Carnival-ram-v5', 'ALE/Casino-v5', 'ALE/Casino-ram-v5', 'ALE/Centipede-v5', 'ALE/Centipede-ram-v5', 'ALE/ChopperCommand-v5', 'ALE/ChopperCommand-ram-v5', 'ALE/CrazyClimber-v5', 'ALE/CrazyClimber-ram-v5', 'ALE/Crossbow-v5', 'ALE/Crossbow-ram-v5', 'ALE/Darkchambers-v5', 'ALE/Darkchambers-ram-v5', 'ALE/Defender-v5', 'ALE/Defender-ram-v5', 'ALE/DemonAttack-v5', 'ALE/DemonAttack-ram-v5', 'ALE/DonkeyKong-v5', 'ALE/DonkeyKong-ram-v5', 'ALE/DoubleDunk-v5', 'ALE/DoubleDunk-ram-v5', 'ALE/Earthworld-v5', 'ALE/Earthworld-ram-v5', 'ALE/ElevatorAction-v5', 'ALE/ElevatorAction-ram-v5', 'ALE/Enduro-v5', 'ALE/Enduro-ram-v5', 'ALE/Entombed-v5', 'ALE/Entombed-ram-v5', 'ALE/Et-v5', 'ALE/Et-ram-v5', 'ALE/FishingDerby-v5', 'ALE/FishingDerby-ram-v5', 'ALE/FlagCapture-v5', 'ALE/FlagCapture-ram-v5', 'ALE/Freeway-v5', 'ALE/Freeway-ram-v5', 'ALE/Frogger-v5', 'ALE/Frogger-ram-v5', 'ALE/Frostbite-v5', 'ALE/Frostbite-ram-v5', 'ALE/Galaxian-v5', 'ALE/Galaxian-ram-v5', 'ALE/Gopher-v5', 'ALE/Gopher-ram-v5', 'ALE/Gravitar-v5', 'ALE/Gravitar-ram-v5', 'ALE/Hangman-v5', 'ALE/Hangman-ram-v5', 'ALE/HauntedHouse-v5', 'ALE/HauntedHouse-ram-v5', 'ALE/Hero-v5', 'ALE/Hero-ram-v5', 'ALE/HumanCannonball-v5', 'ALE/HumanCannonball-ram-v5', 'ALE/IceHockey-v5', 'ALE/IceHockey-ram-v5', 'ALE/Jamesbond-v5', 'ALE/Jamesbond-ram-v5', 'ALE/JourneyEscape-v5', 'ALE/JourneyEscape-ram-v5', 'ALE/Kaboom-v5', 'ALE/Kaboom-ram-v5', 'ALE/Kangaroo-v5', 'ALE/Kangaroo-ram-v5', 'ALE/KeystoneKapers-v5', 'ALE/KeystoneKapers-ram-v5', 'ALE/KingKong-v5', 'ALE/KingKong-ram-v5', 'ALE/Klax-v5', 'ALE/Klax-ram-v5', 'ALE/Koolaid-v5', 'ALE/Koolaid-ram-v5', 'ALE/Krull-v5', 'ALE/Krull-ram-v5', 'ALE/KungFuMaster-v5', 'ALE/KungFuMaster-ram-v5', 'ALE/LaserGates-v5', 'ALE/LaserGates-ram-v5', 'ALE/LostLuggage-v5', 'ALE/LostLuggage-ram-v5', 'ALE/MarioBros-v5', 'ALE/MarioBros-ram-v5', 'ALE/MiniatureGolf-v5', 'ALE/MiniatureGolf-ram-v5', 'ALE/MontezumaRevenge-v5', 'ALE/MontezumaRevenge-ram-v5', 'ALE/MrDo-v5', 'ALE/MrDo-ram-v5', 'ALE/MsPacman-v5', 'ALE/MsPacman-ram-v5', 'ALE/NameThisGame-v5', 'ALE/NameThisGame-ram-v5', 'ALE/Othello-v5', 'ALE/Othello-ram-v5', 'ALE/Pacman-v5', 'ALE/Pacman-ram-v5', 'ALE/Phoenix-v5', 'ALE/Phoenix-ram-v5', 'ALE/Pitfall-v5', 'ALE/Pitfall-ram-v5', 'ALE/Pitfall2-v5', 'ALE/Pitfall2-ram-v5', 'ALE/Pong-v5', 'ALE/Pong-ram-v5', 'ALE/Pooyan-v5', 'ALE/Pooyan-ram-v5', 'ALE/PrivateEye-v5', 'ALE/PrivateEye-ram-v5', 'ALE/Qbert-v5', 'ALE/Qbert-ram-v5', 'ALE/Riverraid-v5', 'ALE/Riverraid-ram-v5', 'ALE/RoadRunner-v5', 'ALE/RoadRunner-ram-v5', 'ALE/Robotank-v5', 'ALE/Robotank-ram-v5', 'ALE/Seaquest-v5', 'ALE/Seaquest-ram-v5', 'ALE/SirLancelot-v5', 'ALE/SirLancelot-ram-v5', 'ALE/Skiing-v5', 'ALE/Skiing-ram-v5', 'ALE/Solaris-v5', 'ALE/Solaris-ram-v5', 'ALE/SpaceInvaders-v5', 'ALE/SpaceInvaders-ram-v5', 'ALE/SpaceWar-v5', 'ALE/SpaceWar-ram-v5', 'ALE/StarGunner-v5', 'ALE/StarGunner-ram-v5', 'ALE/Superman-v5', 'ALE/Superman-ram-v5', 'ALE/Surround-v5', 'ALE/Surround-ram-v5', 'ALE/Tennis-v5', 'ALE/Tennis-ram-v5', 'ALE/Tetris-v5', 'ALE/Tetris-ram-v5', 'ALE/TicTacToe3D-v5', 'ALE/TicTacToe3D-ram-v5', 'ALE/TimePilot-v5', 'ALE/TimePilot-ram-v5', 'ALE/Trondead-v5', 'ALE/Trondead-ram-v5', 'ALE/Turmoil-v5', 'ALE/Turmoil-ram-v5', 'ALE/Tutankham-v5', 'ALE/Tutankham-ram-v5', 'ALE/UpNDown-v5', 'ALE/UpNDown-ram-v5', 'ALE/Venture-v5', 'ALE/Venture-ram-v5', 'ALE/VideoCheckers-v5', 'ALE/VideoCheckers-ram-v5', 'ALE/VideoChess-v5', 'ALE/VideoChess-ram-v5', 'ALE/VideoCube-v5', 'ALE/VideoCube-ram-v5', 'ALE/VideoPinball-v5', 'ALE/VideoPinball-ram-v5', 'ALE/WizardOfWor-v5', 'ALE/WizardOfWor-ram-v5', 'ALE/WordZapper-v5', 'ALE/WordZapper-ram-v5', 'ALE/YarsRevenge-v5', 'ALE/YarsRevenge-ram-v5', 'ALE/Zaxxon-v5', 'ALE/Zaxxon-ram-v5'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tools**"
      ],
      "metadata": {
        "id": "FXfDmDTHfRLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DQN 模型"
      ],
      "metadata": {
        "id": "mgC7RzCmf4gd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P-qBFizwfLv8"
      },
      "outputs": [],
      "source": [
        "class AtariNetDQN(nn.Module):\n",
        "    def __init__(self, num_classes=9, init_weights=True):\n",
        "        super(AtariNetDQN, self).__init__()\n",
        "        self.cnn = nn.Sequential(nn.Conv2d(4, 32, kernel_size=8, stride=4),\n",
        "                                        nn.ReLU(True),\n",
        "                                        nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "                                        nn.ReLU(True),\n",
        "                                        nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "                                        nn.ReLU(True)\n",
        "                                        )\n",
        "        self.classifier = nn.Sequential(nn.Linear(7*7*64, 512),\n",
        "                                        nn.ReLU(True),\n",
        "                                        nn.Linear(512, num_classes)\n",
        "                                        )\n",
        "\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float() / 255.\n",
        "        x = self.cnn(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0.0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1.0)\n",
        "                nn.init.constant_(m.bias, 0.0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                nn.init.constant_(m.bias, 0.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reply buffer"
      ],
      "metadata": {
        "id": "ytEIEzlof8pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayMemory(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def append(self, *transition):\n",
        "        \"\"\"Saves a transition\"\"\"\n",
        "        self.buffer.append(tuple(map(tuple, transition)))\n",
        "\n",
        "    def sample(self, batch_size, device):\n",
        "        \"\"\"Sample a batch of transitions\"\"\"\n",
        "        transitions = random.sample(self.buffer, batch_size)\n",
        "        return (torch.tensor(np.asarray(x), dtype=torch.float, device=device) for x in zip(*transitions))"
      ],
      "metadata": {
        "id": "mx4exAHTgEzc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&emsp;"
      ],
      "metadata": {
        "id": "9NfEqNSXgpnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Agents**"
      ],
      "metadata": {
        "id": "2U-WxZjjgYcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### base agent"
      ],
      "metadata": {
        "id": "V8sRl31hgzZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DQNBaseAgent(ABC):\n",
        "\tdef __init__(self, config):\n",
        "\t\tself.gpu = config[\"gpu\"]\n",
        "\t\tself.device = torch.device(\"cuda\" if self.gpu and torch.cuda.is_available() else \"cpu\")\n",
        "\t\tself.total_time_step = 0\n",
        "\t\tself.training_steps = int(config[\"training_steps\"])\n",
        "\t\tself.batch_size = int(config[\"batch_size\"])\n",
        "\t\tself.epsilon = 1.0\n",
        "\t\tself.eps_min = config[\"eps_min\"]\n",
        "\t\tself.eps_decay = config[\"eps_decay\"]\n",
        "\t\tself.eval_epsilon = config[\"eval_epsilon\"]\n",
        "\t\tself.warmup_steps = config[\"warmup_steps\"]\n",
        "\t\tself.eval_interval = config[\"eval_interval\"]\n",
        "\t\tself.eval_episode = config[\"eval_episode\"]\n",
        "\t\tself.gamma = config[\"gamma\"]\n",
        "\t\tself.update_freq = config[\"update_freq\"]\n",
        "\t\tself.update_target_freq = config[\"update_target_freq\"]\n",
        "\n",
        "\t\tself.replay_buffer = ReplayMemory(int(config[\"replay_buffer_capacity\"]))\n",
        "\t\tself.writer = SummaryWriter(config[\"logdir\"])\n",
        "\n",
        "\t@abstractmethod\n",
        "\tdef decide_agent_actions(self, observation, epsilon=0.0, action_space=None):\n",
        "\t\t### TODO ###\n",
        "\t\t# get action from behavior net, with epsilon-greedy selection\n",
        "\n",
        "\t\treturn NotImplementedError\n",
        "\n",
        "\tdef update(self):\n",
        "\t\tif self.total_time_step % self.update_freq == 0:\n",
        "\t\t\tself.update_behavior_network()\n",
        "\t\tif self.total_time_step % self.update_target_freq == 0:\n",
        "\t\t\tself.update_target_network()\n",
        "\n",
        "\t@abstractmethod\n",
        "\tdef update_behavior_network(self):\n",
        "\t\t# sample a minibatch of transitions\n",
        "\t\tstate, action, reward, next_state, done = self.replay_buffer.sample(self.batch_size, self.device)\n",
        "\t\t### TODO ###\n",
        "\t\t# calculate the loss and update the behavior network\n",
        "\n",
        "\n",
        "\tdef update_target_network(self):\n",
        "\t\tself.target_net.load_state_dict(self.behavior_net.state_dict())\n",
        "\n",
        "\tdef epsilon_decay(self):\n",
        "\t\tself.epsilon -= (1 - self.eps_min) / self.eps_decay\n",
        "\t\tself.epsilon = max(self.epsilon, self.eps_min)\n",
        "\n",
        "\tdef train(self):\n",
        "\t\tepisode_idx = 0\n",
        "\t\twhile self.total_time_step <= self.training_steps:\n",
        "\t\t\tobservation, info = self.env.reset()\n",
        "\t\t\tepisode_reward = 0\n",
        "\t\t\tepisode_len = 0\n",
        "\t\t\tepisode_idx += 1\n",
        "\t\t\twhile True:\n",
        "\t\t\t\tif self.total_time_step < self.warmup_steps:\n",
        "\t\t\t\t\taction = self.decide_agent_actions(observation, 1.0, self.env.action_space)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\taction = self.decide_agent_actions(observation, self.epsilon, self.env.action_space)\n",
        "\t\t\t\t\tself.epsilon_decay()\n",
        "\n",
        "\t\t\t\tnext_observation, reward, terminate, truncate, info = self.env.step(action)\n",
        "\t\t\t\tself.replay_buffer.append(observation, [action], [reward], next_observation, [int(terminate)])\n",
        "\n",
        "\t\t\t\tif self.total_time_step >= self.warmup_steps:\n",
        "\t\t\t\t\tself.update()\n",
        "\n",
        "\t\t\t\tepisode_reward += reward\n",
        "\t\t\t\tepisode_len += 1\n",
        "\n",
        "\t\t\t\tif terminate or truncate:\n",
        "\t\t\t\t\tself.writer.add_scalar('Train/Episode Reward', episode_reward, self.total_time_step)\n",
        "\t\t\t\t\tself.writer.add_scalar('Train/Episode Len', episode_len, self.total_time_step)\n",
        "\t\t\t\t\tprint(f\"[{self.total_time_step}/{self.training_steps}]  episode: {episode_idx}  \\\n",
        "\t\t\t\t\tepisode reward: {episode_reward}  episode len: {episode_len}  epsilon: {self.epsilon}\")\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\t\t\t\tobservation = next_observation\n",
        "\t\t\t\tself.total_time_step += 1\n",
        "\n",
        "\t\t\tif episode_idx % self.eval_interval == 0:\n",
        "\t\t\t\t# save model checkpoint\n",
        "\t\t\t\tavg_score = self.evaluate()\n",
        "\t\t\t\tself.save(os.path.join(self.writer.log_dir, f\"model_{self.total_time_step}_{int(avg_score)}.pth\"))\n",
        "\t\t\t\tself.writer.add_scalar('Evaluate/Episode Reward', avg_score, self.total_time_step)\n",
        "\n",
        "\tdef evaluate(self):\n",
        "\t\tprint(\"==============================================\")\n",
        "\t\tprint(\"Evaluating...\")\n",
        "\t\tall_rewards = []\n",
        "\t\tfor i in range(self.eval_episode):\n",
        "\t\t\tobservation, info = self.test_env.reset()\n",
        "\t\t\ttotal_reward = 0\n",
        "\t\t\twhile True:\n",
        "\t\t\t\tself.test_env.render()\n",
        "\t\t\t\taction = self.decide_agent_actions(observation, self.eval_epsilon, self.test_env.action_space)\n",
        "\t\t\t\tnext_observation, reward, terminate, truncate, info = self.test_env.step(action)\n",
        "\t\t\t\ttotal_reward += reward\n",
        "\t\t\t\tif terminate or truncate:\n",
        "\t\t\t\t\tprint(f\"episode {i+1} reward: {total_reward}\")\n",
        "\t\t\t\t\tall_rewards.append(total_reward)\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\t\t\t\tobservation = next_observation\n",
        "\n",
        "\n",
        "\t\tavg = sum(all_rewards) / self.eval_episode\n",
        "\t\tprint(f\"average score: {avg}\")\n",
        "\t\tprint(\"==============================================\")\n",
        "\t\treturn avg\n",
        "\n",
        "\t# save model\n",
        "\tdef save(self, save_path):\n",
        "\t\ttorch.save(self.behavior_net.state_dict(), save_path)\n",
        "\n",
        "\t# load model\n",
        "\tdef load(self, load_path):\n",
        "\t\tself.behavior_net.load_state_dict(torch.load(load_path))\n",
        "\n",
        "\t# load model weights and evaluate\n",
        "\tdef load_and_evaluate(self, load_path):\n",
        "\t\tself.load(load_path)\n",
        "\t\tself.evaluate()"
      ],
      "metadata": {
        "id": "sS6x1Om8gy1N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DQN_Agent ( 作業重點 )"
      ],
      "metadata": {
        "id": "Xh8yg1UBg7u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AtariDQNAgent(DQNBaseAgent):\n",
        "\tdef __init__(self, config):\n",
        "\t\tsuper(AtariDQNAgent, self).__init__(config)\n",
        "\n",
        "\t\tself.env = gym.make(config[\"env_id\"])\n",
        "\n",
        "\t\tself.test_env = gym.make(config[\"env_id\"])\n",
        "\n",
        "\t\t# initialize behavior network and target network\n",
        "\t\tself.behavior_net = AtariNetDQN(self.env.action_space.n)\n",
        "\t\tself.behavior_net.to(self.device)\n",
        "\t\tself.target_net = AtariNetDQN(self.env.action_space.n)\n",
        "\t\tself.target_net.to(self.device)\n",
        "\t\tself.target_net.load_state_dict(self.behavior_net.state_dict())\n",
        "\n",
        "\t\t# initialize optimizer\n",
        "\t\tself.lr = config[\"learning_rate\"]\n",
        "\t\tself.optim = torch.optim.Adam(self.behavior_net.parameters(), lr=self.lr, eps=1.5e-4)\n",
        "\n",
        "\tdef decide_agent_actions(self, observation, epsilon=0.0, action_space=None):\n",
        "\t\tif random.random() <= epsilon:\n",
        "\t\t\treturn random.randrange(self.env.action_space.n)\n",
        "\t\telse:\n",
        "\t\t\tQ_s = self.behavior_net.forward(observation)\n",
        "\t\t\t_, actions = Q_s.max(dim=1, keepdim=True)\n",
        "\t\t\treturn actions\n",
        "\n",
        "\tdef Q_value(self, net, states, actions):\n",
        "\t\tif net == \"target\":\n",
        "\t\t\tnext_q_values = self.target_net.forward(states).gather(dim=1, index=actions)\n",
        "\t\t\treturn next_q_values\n",
        "\t\telif net == \"behavior\":\n",
        "\t\t\tq_values = self.behavior_net.forward(states).gather(dim=1, index=actions)\n",
        "\t\t\treturn q_values\n",
        "\n",
        "\t# implement DDQN\n",
        "\tdef update_behavior_network(self):\n",
        "\t\tstate, action, reward, next_state, done = self.replay_buffer.sample(self.batch_size, self.device)\n",
        "\n",
        "\t\tnext_action = self.decide_agent_actions(state, self.epsilon)\n",
        "\t\tQ_target = reward + self.gamma * self.Q_value(\"target\", next_state, next_action)\n",
        "\t\tQ_output = self.Q_value(\"behavior\", state, action)\n",
        "\n",
        "\t\tcriterion = nn.Smooth1Loss()\n",
        "\t\tloss = criterion(Q_output, Q_target)\n",
        "\n",
        "\t\tself.writer.add_scalar('DQN/Loss', loss.item(), self.total_time_step)\n",
        "\n",
        "\t\tself.optim.zero_grad()\n",
        "\t\tloss.backward()\n",
        "\t\tself.optim.step()"
      ],
      "metadata": {
        "id": "_REgd9JQhI9z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&emsp;"
      ],
      "metadata": {
        "id": "j66ReT1rhdNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main"
      ],
      "metadata": {
        "id": "WvIN4EPXhe2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # my hyperparameters, you can change it as you like\n",
        "    config = {\n",
        "\t\t\"gpu\": True,\n",
        "\t\t\"training_steps\": 1e8,\n",
        "\t\t\"gamma\": 0.99,\n",
        "\t\t\"batch_size\": 32,\n",
        "\t\t\"eps_min\": 0.1,\n",
        "\t\t\"warmup_steps\": 20000,\n",
        "\t\t\"eps_decay\": 1000000,\n",
        "\t\t\"eval_epsilon\": 0.01,\n",
        "\t\t\"replay_buffer_capacity\": 100000,\n",
        "\t\t\"logdir\": 'log/DQN/',\n",
        "\t\t\"update_freq\": 4,\n",
        "\t\t\"update_target_freq\": 10000,\n",
        "\t\t\"learning_rate\": 0.0000625,\n",
        "        \"eval_interval\": 100,\n",
        "        \"eval_episode\": 5,\n",
        "\t\t\"env_id\": 'ALE/MsPacman-v5',\n",
        "\t}\n",
        "    agent = AtariDQNAgent(config)\n",
        "    agent.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "id": "zY8y_W7ShkYX",
        "outputId": "347722b6-ebad-4cab-8b9e-b86ddd4e79db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-730bae5dcf8b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \t}\n\u001b[1;32m     21\u001b[0m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAtariDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-6e59ea53a523>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                                 \u001b[0mnext_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/env_checker.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecked_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecked_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_step_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py\u001b[0m in \u001b[0;36menv_step_passive_checker\u001b[0;34m(env, action)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;34m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;31m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     assert isinstance(\n\u001b[1;32m    210\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shimmy/atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action_ind)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mis_terminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_truncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mis_truncated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: game_over(): incompatible function arguments. The following argument types are supported:\n    1. (self: ale_py._ale_py.ALEInterface) -> bool\n\nInvoked with: <ale_py._ale_py.ALEInterface object at 0x7c1b0e98a730>; kwargs: with_truncation=False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i5jAMBXIjCD1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}